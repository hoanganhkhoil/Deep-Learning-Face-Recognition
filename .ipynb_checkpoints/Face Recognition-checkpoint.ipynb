{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 200, 1)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Author: Khoi Hoang\n",
    "# Contact: hoanganhkhoil@gmail.com\n",
    "# Project: Face Recognition - Convolutional Neural Network (CNN) with Tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 \n",
    "\n",
    "images = []\n",
    "\n",
    "for file_name in glob.glob('KD_face/*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images.append(im)\n",
    "    \n",
    "for file_name in glob.glob('Henok_face/*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images.append(im)\n",
    "    \n",
    "    \n",
    "labels = []\n",
    "kd = [1, 0]\n",
    "henok = [0, 1]\n",
    "\n",
    "for i in range(100):\n",
    "    labels.append(kd)\n",
    "\n",
    "for i in range(100):\n",
    "    labels.append(henok)\n",
    "    \n",
    "Input = np.array(images)\n",
    "Labels = np.array(labels)\n",
    "\n",
    "print (Input.shape)\n",
    "print (Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 200, 200, 1)\n",
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "images_test = []\n",
    "\n",
    "for file_name in glob.glob('KD_test/*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images_test.append(im)\n",
    "    \n",
    "for file_name in glob.glob('Henok_test/*.jpg'):\n",
    "    im = mpimg.imread(file_name)\n",
    "    im = im[:,:, np.newaxis]\n",
    "    images_test.append(im)\n",
    "    \n",
    "    \n",
    "labels_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    labels_test.append(kd)\n",
    "    \n",
    "for i in range(5):\n",
    "    labels_test.append(henok)\n",
    "    \n",
    "Input_test = np.array(images_test)\n",
    "Labels_test = np.array(labels_test)\n",
    "\n",
    "print (Input_test.shape)\n",
    "print (Labels_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 14359.2638696, Accuracy: 0.55\n",
      "Epoch: 2, Loss: 7640.14626463, Accuracy: 0.68\n",
      "Epoch: 4, Loss: 5428.49276476, Accuracy: 0.76\n",
      "Epoch: 6, Loss: 2341.06056028, Accuracy: 0.825\n",
      "Epoch: 8, Loss: 1060.48369693, Accuracy: 0.9\n",
      "Loss: 159.960494995, Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Create placeholders\n",
    "X = tf.placeholder(tf.float32, [None, 200, 200, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# Create variables\n",
    "K = 6   # first layer output channels\n",
    "L = 12  # second layer output channels\n",
    "M = 24  # third layer output channels\n",
    "N = 200 # fully connected layer output channels\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([6,6,1,K], stddev=0.1))   # 1 input channels (Depth), K output channels (Depth)\n",
    "B1 = tf.Variable(tf.ones([K])/10)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([5,5,K,L], stddev=0.1))   # K input channels, L output channels\n",
    "B2 = tf.Variable(tf.ones([L])/10)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([4,4,L,M], stddev=0.1))   # L input channels, M output channels\n",
    "B3 = tf.Variable(tf.ones([M])/10)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([50*50*M,N], stddev=0.1))   # 7x7xM input channels, N output channels\n",
    "B4 = tf.Variable(tf.ones([N])/10)\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([N,2], stddev=0.1))       # N input channels, 10 output channels\n",
    "B5 = tf.Variable(tf.ones([2])/10)\n",
    "\n",
    "# Create model\n",
    "stride1 = 1     # output = 200 x 200 pixel\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride1, stride1, 1], padding='SAME') + B1)\n",
    "\n",
    "stride2 = 2     # output = 100 x 100 pixel\n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride2, stride2, 1], padding='SAME') + B2)\n",
    "\n",
    "stride3 = 2     # output = 50 x 50 pixel\n",
    "Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride3, stride3, 1], padding='SAME') + B3)\n",
    "\n",
    "# Reshape input for the fully connected layer\n",
    "YY = tf.reshape(Y3, [-1, 50*50*M])\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "\n",
    "# Dropout Fully connected layer\n",
    "Ydrop = tf.nn.dropout(Y4, pkeep)\n",
    "\n",
    "# Output\n",
    "Ylogits = tf.matmul(Ydrop, W5) + B5\n",
    "\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "# Loss function\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "# Accuracy\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(10):\n",
    "    train_dict = {X: Input, Y_: Labels, lr: 0.0001, pkeep: 0.75}\n",
    "\n",
    "    # Train\n",
    "    sess.run(optimizer, feed_dict=train_dict)\n",
    "\n",
    "    # Accuracy\n",
    "    if i % 2 == 0:\n",
    "        A,C = sess.run([accuracy, loss], feed_dict=train_dict)\n",
    "        print (\"Epoch: %s, Loss: %s, Accuracy: %s\" % (i, sum(C), A))\n",
    "        \n",
    "\n",
    "# Test\n",
    "test_dict = {X: Input_test, Y_: Labels_test, lr: 0.0001, pkeep: 0.75}\n",
    "\n",
    "A,C = sess.run([accuracy, loss], feed_dict=test_dict)\n",
    "\n",
    "print (\"Loss: %s, Accuracy: %s\" % (sum(C), A))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: KD face\n",
      "Actual: Kd face\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/Users/travis/miniconda3/conda-bld/opencv_1498147116090/work/opencv-3.2.0/modules/imgproc/src/drawing.cpp:1701: error: (-215) 0 <= shift && shift <= XY_SHIFT && thickness >= 0 in function PolyLine\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8eeb7bd10de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_face\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Face\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# Press Enter to see next image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/travis/miniconda3/conda-bld/opencv_1498147116090/work/opencv-3.2.0/modules/imgproc/src/drawing.cpp:1701: error: (-215) 0 <= shift && shift <= XY_SHIFT && thickness >= 0 in function PolyLine\n"
     ]
    }
   ],
   "source": [
    "Y_predict = sess.run(Y, feed_dict=test_dict)\n",
    "\n",
    "for i in range(len(Labels_test)):\n",
    "    if np.argmax(Y_predict[i]) == 0:\n",
    "        predicted_face = \"KD face\"\n",
    "    elif np.argmax(Y_predict[i]) == 1:\n",
    "        predicted_face = \"Henok face\"\n",
    "        \n",
    "    if np.argmax(Labels_test[i]) == 0:\n",
    "        actual_face = \"Kd face\"\n",
    "    elif np.argmax(Labels_test[i]) == 1:\n",
    "        actual_face = \"Henok face\"\n",
    "        \n",
    "    print (\"Predicted: %s\" % (predicted_face))\n",
    "    print (\"Actual: %s\" % (actual_face))\n",
    "    \n",
    "    image = images[i]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(image,predicted_face,(50,50), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Face\", image)\n",
    "    cv2.waitKey(0)            # Press Enter to see next image.\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
